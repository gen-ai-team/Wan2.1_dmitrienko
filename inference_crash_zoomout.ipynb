{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2024-2025 The Alibaba Wan Team Authors. All rights reserved.\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/submodules/Wan2_1/wan/modules/model.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n",
      "/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/submodules/Wan2_1/wan/modules/model.py:39: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @amp.autocast(enabled=False)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import torch\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "from datetime import datetime\n",
    "from ipywidgets import interact, interactive, fixed, widgets\n",
    "from IPython.display import Video\n",
    "\n",
    "import wan\n",
    "from wan.configs import WAN_CONFIGS, SIZE_CONFIGS, MAX_AREA_CONFIGS, SUPPORTED_SIZES\n",
    "from wan.utils.prompt_extend import DashScopePromptExpander, QwenPromptExpander\n",
    "from wan.utils.utils import cache_video, cache_image\n",
    "from inference_lora import lora_name_to_path, add_lora_tag, LoraModel\n",
    "from accelerate import PartialState # Can also be Accelerator of AcceleratorState\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"i2v-14B\"\n",
    "use_prompt_extend=False\n",
    "prompt_extend_method=False\n",
    "prompt_extend_target_lang=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0e1932efd44ab2b7af0920f9bbb9ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model\n",
    "ckpt_dir = '/home/jovyan/dmitrienko/workspace/checkpoints/pretrained/Wan2.1-I2V-14B-480P' \n",
    "pipe_cls = wan.WanI2V\n",
    "cfg = WAN_CONFIGS[task]\n",
    "\n",
    "pipe = pipe_cls(\n",
    "    config=cfg,\n",
    "    checkpoint_dir=ckpt_dir,\n",
    "    device_id='0',\n",
    "    rank=0,\n",
    ")\n",
    "pipe.model = LoraModel(pipe.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_name_to_path = {\n",
    "    #\"i2v_CR4$h_Z00M0UT_256_r128_lr1e-4_bs4\": \"/home/jovyan/dmitrienko/workspace/checkpoints/wan14b_i2v/higgsfield_crash_zoom_out_256_lora128_lr1e-4_bs4_1gpu/20250406_16-59-05/\",\n",
    "    \"i2v_CR4$h_Z00M0UT_480_r128_lr1e-4_bs2\": \"/home/jovyan/dmitrienko/workspace/checkpoints/wan14b_i2v/higgsfield_crash_zoom_out_480_lora128_lr1e-4_bs2_2gpus/20250405_18-33-10/\",\n",
    "    # \"i2v_CR4$h_Z00M0UT_512_r128_lr1e-4_bs4\": \"/home/jovyan/dmitrienko/workspace/checkpoints/wan14b_i2v/higgsfield_crash_zoom_out_512_lora128_lr1e-4_bs4_1gpu/20250406_17-26-40/\",\n",
    "    # \"i2v_CR4$h_Z00M0UT_512_r128_lr5e-5_bs4\": \"/home/jovyan/dmitrienko/workspace/checkpoints/wan14b_i2v/higgsfield_crash_zoom_out_512_lora128_lr5e-5_bs4_1gpu/20250406_17-18-48/\",\n",
    "\n",
    "}\n",
    "\n",
    "# Optimal checkpoint\n",
    "default_epoch = {\n",
    "    \"i2v_CR4$h_Z00M0UT_480_r128_lr1e-4_bs2\": 'epoch50',\n",
    "}\n",
    "\n",
    "lora_name_to_tag = {\n",
    "    \"i2v_CR4$h_Z00M0UT_480_r128_lr1e-4_bs2\": \"CR4$h Z00M0UT\",\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8162d5c8f0f4c008826205839e49961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='LoRA Name:', options=('i2v_CR4$h_Z00M0UT_480_r128_lr1e-4_bs2', 'None'), value='i2v_CR4$h…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lora_name_widget = widgets.Dropdown(\n",
    "    options=list(lora_name_to_path.keys()) + ['None'],\n",
    "    value=list(lora_name_to_path.keys())[-1],\n",
    "    description=\"LoRA Name:\",\n",
    ")\n",
    "display(lora_name_widget,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593a1691697c4142b2a7a45882690c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='LoRA epoch:', index=9, options=('epoch5', 'epoch10', 'epoch15', 'epoch20', 'epoch25', 'e…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lora_name=lora_name_widget.value\n",
    "\n",
    "if lora_name not in ['None', 'opensource_civitai', 'opensource_remade_rotation']:\n",
    "    epochs = [p for p in os.listdir(lora_name_to_path[lora_name]) if p.startswith('epoch')]\n",
    "else:\n",
    "    epochs = ['0']\n",
    "epoch_widget = widgets.Dropdown(\n",
    "    options=epochs,\n",
    "    value=default_epoch[lora_name] if lora_name in default_epoch else epochs[-1],\n",
    "    description=\"LoRA epoch:\",\n",
    ")\n",
    "\n",
    "# Display widgets\n",
    "display(epoch_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/jovyan/dmitrienko/workspace/checkpoints/wan14b_i2v/higgsfield_crash_zoom_out_480_lora128_lr1e-4_bs2_2gpus/20250405_18-33-10/epoch50/adapter_model.safetensors\n",
      "Reading file into memory...\n",
      "Read 1.34GB into memory\n",
      "Loading tensors...\n",
      "Successfully loaded 960 tensors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/dmitrienko/workspace/checkpoints/wan14b_i2v/higgsfield_crash_zoom_out_480_lora128_lr1e-4_bs2_2gpus/20250405_18-33-10/epoch50/adapter_model.safetensors'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_scale = 1.\n",
    "if lora_name != 'None':\n",
    "    if lora_name not in ['opensource_arc']:\n",
    "        lora_path = os.path.join(lora_name_to_path[lora_name], epoch_widget.value)\n",
    "    else:\n",
    "        lora_path = lora_name_to_path[lora_name]\n",
    "    lora_path = os.path.join(lora_path, 'adapter_model.safetensors')\n",
    "    pipe.model.apply_lora(\n",
    "        lora_path,\n",
    "        lora_scale=lora_scale\n",
    "    )\n",
    "else:\n",
    "    lora_path = 'None'\n",
    "    if isinstance(pipe.model, LoraModel):\n",
    "        pipe.model.remove_lora()\n",
    "lora_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d14e4f26f74866962f23a4350744ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=40, description='Diffusion steps:', max=50, min=15, style=SliderStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2406b0718b7b468c9adf4163c5ede142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Video frames:', index=1, options=(33, 65, 97), value=65)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab10ee2141c4dd49809c223c13b3af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Crop image to square')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f41d91b008c40138db23783fd1db465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Video size:', index=7, options=('720*1280', '1280*720', '480*832', '832*480', '256*144',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee0019dadbfd4fd2af05c050c96c2320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=44, description='Base Seed:', max=100000, min=-1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea9e966c761492b934b49de8c57932a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=5, description='Scale shift:', max=10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8b2313113f4f419bfc725d7c587699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=5, description='Guidance scale:', max=10, style=SliderStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps_widget = widgets.IntSlider(\n",
    "    value=40, min=15, max=50, step=1,\n",
    "    description=\"Diffusion steps:\",\n",
    "     style= {'description_width': 'initial'}\n",
    ")\n",
    "frame_widget = widgets.Dropdown(\n",
    "    value=65,\n",
    "    description=\"Video frames:\",\n",
    "    options=[33, 65, 97],\n",
    ")\n",
    "size_widget = widgets.Dropdown(\n",
    "    options=list(SIZE_CONFIGS.keys()),\n",
    "    value='512*512',\n",
    "    description=\"Video size:\",\n",
    ")\n",
    "base_seed_widget = widgets.IntSlider(\n",
    "    value=44, min=-1, max=100000, step=1,\n",
    "    description=\"Base Seed:\",\n",
    ")\n",
    "sample_shift_widget = widgets.IntSlider(\n",
    "    value=5., min=0, max=10, step=1,\n",
    "    description=\"Scale shift:\",\n",
    ")\n",
    "guide_scale_widget = widgets.IntSlider(\n",
    "    value=5., min=0, max=10, step=1,\n",
    "    description=\"Guidance scale:\",\n",
    "    style= {'description_width': 'initial'}\n",
    ")\n",
    "square_image_widget = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description=\"Crop image to square\",\n",
    ")\n",
    "display(\n",
    "    steps_widget, frame_widget,\n",
    "    square_image_widget,\n",
    "    size_widget, base_seed_widget, \n",
    "    sample_shift_widget, guide_scale_widget, \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимальное количество шагов диффузии:  20-40, при 20 возможны небольшие артефакты...\n",
    "\n",
    "Оптимальный Scale shift: 5-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image = '/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/photo_2025-02-19_18-03-37.jpg'\n",
    "prompt = 'A plush toy shaped like an avocado. It has a Bright green exterior representing the avocado flesh. The toy is made of soft, fuzzy fabric, making it look cuddly.'\n",
    "\n",
    "image = '/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/cosmos.png'\n",
    "prompt = 'an astronaut standing on a rocky, barren lunar or planetary surface, gazing at a large, bright moon or planet rising the horizon. The landscape is dusty and uneven, with craters and small boulders scattered around. The sky is dark, possibly space, filled with stars. The astronaut is wearing a white space suit with a helmet and a backpack-like life support system. The scene gives a feeling of solitude and exploration in an otherworldly environment.'\n",
    "\n",
    "image = '/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/gagarin.png'\n",
    "prompt = 'a smiling astronaut wearing a vintage space suit. The suit is orange with a helmet that has a clear visor and communication equipment visible. The person appears to be preparing for or returning from a space mission. The overall appearance, especially the design of the suit and helmet, resembles those used during the early Soviet space program.'\n",
    "\n",
    "image = '/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/rocket2.jpg'\n",
    "prompt = \"the rocket ascending through the sky. Bright flames and thick plumes of exhaust trail behind the rocket, emphasizing its powerful thrust as it pierces through a cloudy sky. The rocket body has white and metallic sections, with orange and black bands near the top. Camera is tracking the rocket, gradually moves up.\"\n",
    "\n",
    "\n",
    "prompt = 'A white-haired maiden wearing a white dress by the sea. The beach is peaceful. Ultra-HD, hyper detailed.'\n",
    "image = '/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/freepik/render.jpeg'\n",
    "\n",
    "prompt = \"Close-up fisheye shot inside an elevator. A model stands confidently, holding a tiny Chihuahua wearing a sequined pink sweater. The model, looking directly at the camera, is dressed in a bold, cobalt blue blazer with exaggerated, sculptural shoulders and matching leather gloves. Their expression is neutral and poised, contrasting the Chihuahua’s nervous energy. The metallic elevator walls create surreal, warped reflections of both the model and the tiny dog.\"\n",
    "image = '/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/freepik/elevator.png'\n",
    "\n",
    "prompt = 'A smiling woman with glowing green eyeshadow that highlights her eyes. She wears green blazer. The soft gradient background in shades of dark green complements her makeup, creating a vibrant yet serene composition filled with positivity. fashion magazine cover, vintage, photographed in the style of Félix Valiente. Editorial fashion. Film grain. Cinematic.'\n",
    "image = '/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/freepik/black_woman.jpeg'\n",
    "\n",
    "prompt = \"An enchanting indoor garden scene, featuring a serene woman in a lush greenery.\\\n",
    " Peach flowers everywhere,  wide shot framing to capture the entire scene, including the subject and the surrounding environment. \\\n",
    " The vintage architecture, with tall columns overgrown with ivy, creates a perfect blend of nature and classic elegance. \"\n",
    "image = '/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/freepik/girl_in_garden.png'\n",
    "\n",
    "prompt = 'Dorothy’s ruby-red shoes resting on the Yellow Brick Road. The person wearing these shoes is likely in their twenties or thirties, with a sharp sense of style and a mischievous glint in their eye. They might have a sleek bob or tousled curls, bold eyeliner, and an outfit that mixes retro charm with modern quirk—think high-waisted shorts, a tucked-in graphic tee, and maybe even a funky hat they found at a thrift shop and insist makes the whole look.'\n",
    "image = '/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/freepik/shoes.png'\n",
    "# image = '/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/photo_2025-02-19_18-03-37 (2).jpg'\n",
    "# prompt = \"This plush toy is shaped like a popsicle and has a fun, relaxed 'cool guy' pose. It has a Bright pink exterior. The toy is made of soft, fuzzy fabric, making it look cuddly. It’s leaning back casually, propped up on a few colorful books, like it's chilling.\"\n",
    "\n",
    "# prompt = 'This is an adorable plush toy of a penguin wearing a yellow and orange inflatable swim ring. There is a clear white background. The penguin has a chubby body, a round orange beak, small flippers at its sides, and a sweet, calm expression.'\n",
    "# image = '/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/samokat/photo_2025-04-09_17-25-02.jpg'\n",
    "\n",
    "# prompt = 'This is an adorable plush toy of a white bear wearing a yellow and orange inflatable swim ring. There is a clear white background. The penguin has a chubby body, a round orange beak, small flippers at its sides, and a sweet, calm expression.'\n",
    "# image = '/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/samokat/photo_2025-04-09_17-25-00.jpg'\n",
    "\n",
    "# prompt = 'This is an adorable flat plush toy of a capybara. There is a clear white background.'\n",
    "# image = '/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/samokat/photo_2025-04-09_17-25-00 (2).jpg'\n",
    "\n",
    "\n",
    "\n",
    "# prompt = 'A wooden comb for hair. The background is clear white.'\n",
    "# image = '/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/samokat/photo_2025-04-09_17-24-59.jpg'\n",
    "\n",
    "\n",
    "# prompt = \"Summer beach vacation style, a white cat wearing sunglasses sits on a surfboard. \\\n",
    "# The fluffy-furred feline gazes directly at the camera with a relaxed expression. \\\n",
    "# Blurred beach scenery forms the background featuring crystal-clear waters, distant green hills, and a blue sky dotted with white clouds.\\\n",
    "# The cat assumes a naturally relaxed posture, as if savoring the sea breeze and warm sunlight.\\\n",
    "# A close-up shot highlights the feline's intricate details and the refreshing atmosphere of the seaside.\"\n",
    "# image = \"/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/submodules/Wan2_1/examples/i2v_input.JPG\"\n",
    "\n",
    "# prompt = \"A majestic horse rearing on its hind legs in a lush green field under a partly cloudy sky.\\\n",
    "# The horse has a shiny, muscular coat with a dark mane and tail, wearing a light-colored halter.\"\n",
    "# image = \"/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/horse.jpg\"\n",
    "\n",
    "# prompt = \"The medium shot of a woman. She has long, straight, dark brown hair parted down the middle and a calm. She is wearing a sleek, fitted, gray long-sleeve hooded top made of a slightly shiny, smooth material.\"\n",
    "# image = \"/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/girl_medium.jpeg\"\n",
    "\n",
    "# prompt = \"A red Porsche 911 on the road in the mountains.\"\n",
    "# image = \"/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/car.jpg\"\n",
    "\n",
    "# prompt = \"The overweight boy rides the bicycle down the dirt road as he descends the hill, with a shocked expression.\"\n",
    "# image = \"/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/videoframe_0.png\"\n",
    "\n",
    "# prompt = \"The cartoonish boy stands ready with his backpack\"\n",
    "# image = \"/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/boy.png\"\n",
    "\n",
    "# prompt = \"The video shows a man seated on a chair.\"\n",
    "# image = \"/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/man.png\"\n",
    "\n",
    "# prompt = \"The video features a wooden chair with a blue cushion.\"\n",
    "# image = \"/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/chair.png\"\n",
    "\n",
    "\n",
    "# prompt = \"A hyper-realistic 3D close-up of a joyful grey cat with soft, well-defined fur. The cat has striking green eyes reflecting ambient light. It wears a green hoodie, and its pink nose and whiskers are visible. The background is dark with soft green and blue lights creating a cinematic depth. The lighting is warm and white, enhancing the lifelike details of its fur, eyes, and facial expression\"\n",
    "# prompt = \"A hyper-realistic 3D  grey cat with soft, well-defined fur. It wears a green hoodie.\"\n",
    "# image = '/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/sbercat/347400964_17982922346473644_951074851559425243_n.jpg'\n",
    "\n",
    "# prompt = \"A hyper-realistic 3D  model joyful grey cat with soft, well-defined fur. The cat has striking green eyes reflecting ambient light. It wears a green hoodie, and its pink nose and whiskers are visible. He stands with his arms outstretched at his sides. The background is dark with soft green and blue lights creating a cinematic depth. The lighting is warm and white, enhancing the lifelike details of its fur, eyes, and facial expression\"\n",
    "# image = '/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/submodules/Wan2_1/examples/sbercat/347418747_17982922316473644_1515624070986201305_n.jpg'\n",
    "\n",
    "# prompt = \"A high-resolution cinematic video of a seagull standing on a stone ledge near a canal in a European city. The seagull moves its head, looks around, and occasionally flaps its wings. The scene is illuminated by natural daylight, creating a lively urban atmosphere.\"\n",
    "# image = '/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/submodules/Wan2_1/examples/images/photo_2025-04-01_16-22-03.jpg'\n",
    "\n",
    "# prompt = \"A cinematic video of a towering, realistic Gundam mecha standing in an open square under a clear blue sky. The scene has a futuristic, high-tech atmosphere.\"\n",
    "# image = '/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/submodules/Wan2_1/examples/images/photo_2025-04-01_16-22-13.jpg'\n",
    "\n",
    "# prompt = 'The towering, realistic Gundam mecha is standing in an open square under a clear blue sky. '\n",
    "# image = '/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/submodules/Wan2_1/examples/images/photo_2025-04-01_16-22-10.jpg'\n",
    "\n",
    "# prompt = \"Chinese ancient tower in the courtyard of a traditional Chinese temple.\"\n",
    "# image = \"/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/photo_2025-04-01_16-22-10.jpg\"\n",
    "\n",
    "# prompt = 'A cinematic video of an old red telephone booth with a WiFi sign, standing alone on a quiet city street. Occasional pedestrians and cars pass by, adding a subtle urban atmosphere.'\n",
    "# image = '/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/submodules/Wan2_1/examples/images/photo_2025-04-01_16-22-07.jpg'\n",
    "\n",
    "\n",
    "# prompt = \"An animated scene featuring a small, furry creature with oversized round ears, large expressive eyes, and a friendly face. The character sits inside a wooden crate, surrounded by warm, dim lighting.\"\n",
    "# image = '/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/_normal.jpg'\n",
    "\n",
    "# prompt = \"An animated scene featuring a small, furry creature with oversized round ears, large expressive eyes, and a friendly face. The character stand in the room, surrounded by warm, dim lighting.\"\n",
    "# image = '/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/4281c0dd8e075c977b34f7e7479388ba.jpg'\n",
    "\n",
    "# prompt = \"There is a large, juicy cheeseburger with a sesame seed bun. The burger is stacked high with two slices of cheddar cheese, crisp green lettuce, thick tomato slices, and a well-cooked beef patty.\\\n",
    "# A container of golden crispy French fries is near the burger. \\\n",
    "# Also there’s a red soft drink cup with a white lid and a straw, completing the classic fast food trio.\"\n",
    "# image = \"/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/fastfood.jpg\"\n",
    "\n",
    "# prompt = \"a pair of low-top sneakers with a worn and distressed look. The shoes are black with off-white laces and a beige rubber sole\"\n",
    "# image = \"/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/keds.jpg\"\n",
    "\n",
    "# prompt = \"a woman with a serene, mysterious expression, often described as a subtle, enigmatic smile. \\\n",
    "# Her dark hair is long and flows over her shoulders, and she wears a dark, modest dress with a fine embroidered neckline and sheer veil.\"\n",
    "# image = \"/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/800px-Mona_Lisa,_by_Leonardo_da.png\"\n",
    "\n",
    "# prompt = \"The video shows a young woman with blonde hair styled in a messy bun, wearing a distressed green jacket and a white top. Her outfit shows signs of wear, adding a rugged texture that's complemented by the rustic.\"\n",
    "# image = \"/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/blonde.png\"\n",
    "\n",
    "# prompt = \"The video shows an animated character in traditional East Asian attire, his gray hair tied in a bun and a confident smile on his face. He is situated in an ancient-style street, adorned with red lanterns, imbuing the scene with a festive or cultural ambiance.\"\n",
    "# image = \"/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/images/pixar_character.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CR4$h Z00M0UT Dorothy’s ruby-red shoes resting on the Yellow Brick Road. The person wearing these shoes is likely in their twenties or thirties, with a sharp sense of style and a mischievous glint in their eye. They might have a sleek bob or tousled curls, bold eyeliner, and an outfit that mixes retro charm with modern quirk—think high-waisted shorts, a tucked-in graphic tee, and maybe even a funky hat they found at a thrift shop and insist makes the whole look.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [03:51<00:00,  5.79s/it]\n"
     ]
    }
   ],
   "source": [
    "size = size_widget.value\n",
    "sample_steps = int(steps_widget.value)\n",
    "frame_num = int(frame_widget.value)\n",
    "sample_shift = sample_shift_widget.value # if \"i2v\" not in task or size not in [\"832*480\", \"480*832\"] else 3.0\n",
    "guide_scale = guide_scale_widget.value\n",
    "base_seed=base_seed_widget.value\n",
    "square_image = square_image_widget.value\n",
    "\n",
    "if lora_name != 'None':\n",
    "    trigger_words = [v for k, v in lora_name_to_tag.items() if k in lora_name][0]\n",
    "    prompt = f\"{trigger_words} {prompt}\"\n",
    "    \n",
    "else:\n",
    "    prompt += ' Сamera zoom out suddenly.'\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "im = Image.open(image).convert(\"RGB\")\n",
    "if square_image:\n",
    "    new_height = int(size.split('*')[0])\n",
    "    new_width = int(size.split('*')[1])\n",
    "\n",
    "    if im.size[1] > im.size[0]:\n",
    "        im = im.resize(( new_height, int(im.size[1]/im.size[0] * new_height)))\n",
    "    else:\n",
    "        im = im.resize(( int(im.size[0]/im.size[1] * new_width), new_width))\n",
    "\n",
    "    width, height = im.size   # Get dimensions\n",
    "\n",
    "    left = (width - new_width)/2\n",
    "    top = (height - new_height)/2\n",
    "    right = (width + new_width)/2\n",
    "    bottom = (height + new_height)/2\n",
    "\n",
    "    # Crop the center of the image\n",
    "    im = im.crop((left, top, right, bottom))\n",
    "\n",
    "output = pipe.generate(\n",
    "    prompt,\n",
    "    im,\n",
    "    max_area=MAX_AREA_CONFIGS[size],\n",
    "    frame_num=frame_num,\n",
    "    shift=sample_shift,\n",
    "    sample_solver=\"unipc\",\n",
    "    sampling_steps=sample_steps,\n",
    "    guide_scale=guide_scale,\n",
    "    seed=base_seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if lora_path != 'None':\n",
    "    save_dir = f\"/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/outputs/\\\n",
    "{task}_{lora_name}_{size}/{lora_path.split('/')[-2] if lora_path.split('/')[-2] != '' else lora_path.split('/')[-3]}\"\n",
    "else:\n",
    "    save_dir = f\"/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/outputs/\\\n",
    "{task}_{lora_name}_{size}/\"\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "suffix = \".png\" if \"t2i\" in task else \".mp4\"\n",
    "formatted_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "formatted_prompt = prompt.replace(\" \", \"_\").replace(\"/\", \"_\")[:100]\n",
    "save_file = f\"lorascale{lora_scale}_{sample_steps}steps_{formatted_prompt}_{formatted_time}{suffix}\"\n",
    "save_file = os.path.join(save_dir, save_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving generated video to /home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/outputs/i2v-14B_i2v_CR4$h_Z00M0UT_480_r128_lr1e-4_bs2_512*512/epoch50/lorascale1.0_40steps_CR4$h_Z00M0UT_Dorothy’s_ruby-red_shoes_resting_on_the_Yellow_Brick_Road._The_person_wearing_these_sh_20250415_184718.mp4\n"
     ]
    }
   ],
   "source": [
    "# Save output\n",
    "if \"t2i\" in task:\n",
    "    print(f\"Saving generated image to {save_file}\")\n",
    "    cache_image(output.squeeze(1)[None], save_file, nrow=1, normalize=True, value_range=(-1, 1))\n",
    "else:\n",
    "    print(f\"Saving generated video to {save_file}\")\n",
    "    cache_video(output[None], save_file, fps=cfg.sample_fps, nrow=1, normalize=True, value_range=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"/home/jovyan/dmitrienko/workspace/diffusion-pipe_dmitrienko/Wan2_1/examples/outputs/i2v-14B_i2v_CR4$h_Z00M0UT_480_r128_lr1e-4_bs2_512*512/epoch50/lorascale1.0_40steps_CR4$h_Z00M0UT_Dorothy’s_ruby-red_shoes_resting_on_the_Yellow_Brick_Road._The_person_wearing_these_sh_20250415_184718.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
